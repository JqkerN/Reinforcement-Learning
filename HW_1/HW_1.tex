 \documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{amsmath}
\usepackage[labelsep=period]{caption} % Figur. istället för Figur:
\usepackage{relsize}
\usepackage{multirow}
\usepackage[export]{adjustbox}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{array}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{parskip}

\title{Reinforcement Learning\\
       Homework 1}

\author{Ilian Corenliussen, 950418-2438, ilianc@kth.se\\ 
        Daniel Hirsch, 960202-5737, dhirsch@kth.se}
\date{November 2020}

\begin{document}

\maketitle

\section{Machine Replacement}
\subsection*{a)}
\textbf{State space:} $S = \{P(perfect), W(worn), B(broken)\} $\\
\textbf{Actions}: $A = \{ C (continue), R(replace) \}$\\
\textbf{Rewards:} $r(P,C) = 0$, $r(W,C) = -\frac{c}{2}$, $r(B,C) = -c$, $r(P, R) = -R$, $r(W, R) = -R$, $r(B, R) = -R$


The transition probability for replace should always be 1 to go from any state to perfect state, i.e. $p(P|s, R) = 1$ for all $s \in S$.  
\[
		P(replace) = \begin{bmatrix}
		        1 & 0 & 0 \\
		        1 & 0 & 0\\
		        1 & 0 & 0
		        \end{bmatrix}
\]
The probability to go from one state to a more worn state when continuing is modeled with the probability $\theta$, i.e. $p(W|P,C)=\theta, p(B|W,C)=\theta$. The probability to stay in the current state will then be $p(P|P,C)=p(W|W,C)=1-\theta$ and the probability to stay in broken when the current state is broken should be equal to 1.
\[
		P(continue) = \begin{bmatrix}
		        1-\theta & \theta & 0 \\
		        0 & 1-\theta & \theta\\
		        0 & 0 & 1
		        \end{bmatrix}
\]
\subsection*{b)}
\textbf{Bellman equation:} $u_{t}^{\star}\left(s_{t}\right)=\max _{a \in A_{s_{t}}}\left[r_{t}\left(s_{t}, a\right)+\sum_{j \in S} p_{t}\left(j \mid s_{t}, a\right) u_{t+1}^{\star}\left(s_{t}, a, j\right)\right]$

\subsubsection*{Solution:}
\begin{equation}
u_{2}^{*}(s_t \in S)  = 0
\end{equation}

\begin{equation}
u_{1}^{*}(P) = \max\{0, -R\} = 0
\end{equation}

\begin{equation}
u_{1}^{*}(W) = \max\{-\frac{c}{2}, -R\} = -\frac{c}{2} = -3
\end{equation}

\begin{equation}
u_{1}^{*}(B) = \max\{-c, -R\} = -c = -6
\end{equation}

\begin{equation}
    u_{0}^{*}(P) = \max
    \left\{\begin{matrix}
    C: & 0 + \Theta u_{1}^{*}(W) + (1 - \Theta)u_{1}^{*}(P) \\
    R: & -R + u_{1}^{*}(P)
    \end{matrix}\right\}
    = -1.5
\end{equation}

\begin{equation}
    u_{0}^{*}(W) = \max
    \left\{\begin{matrix}
    C: & -\frac{c}{2} + \Theta u_{1}^{*}(B) + (1 - \Theta)u_{1}^{*}(W) \\
    R: & -R +  u_{1}^{*}(P)
    \end{matrix}\right\}
    = -7.5
\end{equation}

\begin{equation}
    u_{0}^{*}(B) = \max
    \left\{\begin{matrix}
    C: & -c + u_{1}^{*}(B) \\
    R: & -R + u_{1}^{*}(P)
    \end{matrix}\right\}
    = -8
\end{equation}






\subsubsection*{Answer:}
$$u^*_0(Worn)= -7.5$$
$$a^*_0(Broken)=Replace$$


\section{Optimal Stopping}
\subsection*{a)}
\subsubsection*{Motivation:}
\textbf{Rewards:} Non-terminal: $r((t,n), S) = \frac{n}{t}$ and $r((t, n), C) = 0$
for $t < T$. \\
Terminal: $r_T (T, n) = \frac{n}{T}$ (Forced to 




\subsubsection*{Answer:}
\textit{Number of states:}

\subsection*{b)}
\subsection*{c)}
\subsection*{d)}

\end{document}
